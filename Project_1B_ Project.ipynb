{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n",
      "/home/workspace/event_data\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "#commented out ' + '/event_data'\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "print(filepath)\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables\n",
    "### The section below has been commented out - mentor pointed out in a message and gave us a dropbox link to download one\n",
    "### large data file: https://www.dropbox.com/s/acrs9k66q34kwkb/event_datafile_new.csv?dl=0.\n",
    "#### This section left on purpose, for continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please refer to statement above - this section commented out\n",
    "# initiating an empty list of rows that will be generated from each filefull_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "#for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "#    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "#        # creating a csv reader object \n",
    "#        csvreader = csv.reader(csvfile) \n",
    "#        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    " #       for line in csvreader:\n",
    " #           #print(line)\n",
    " #           full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "#csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "#with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    #writer = csv.writer(f, dialect='myDialect')\n",
    "    #writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                #'level','location','sessionId','song','userId'])\n",
    "    #for row in full_data_rows_list:\n",
    "        #if (row[0] == ''):\n",
    "            #continue\n",
    "        #writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows in file:\n",
      "\n",
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "print(\"number of rows in file:\\n\")\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Create a Keyspace \n",
    "try:\n",
    "    session.execute(\"\"\"CREATE KEYSPACE IF NOT EXISTS udacity\n",
    "                        WITH REPLICATION = \n",
    "                        {'class': 'SimpleStrategy', 'replication_factor': 1}\n",
    "                    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 3 distinct queries to produce specified output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUERY 1:\n",
    "### 1. Give the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "### For this query I used (session_id, item_in_session) as a composite partition key where session_id is the partition key and item_session is a clustering key, since the query asks for a specific session_id and item_in_session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "query1 = \"CREATE TABLE IF NOT EXISTS song_info (sessionid int, item_in_session int, artist_name text, song_length float, song_title text, PRIMARY KEY(sessionid, item_in_session))\"\n",
    "try:\n",
    "    session.execute(query1)\n",
    "except Exception as e:\n",
    "    print(e)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## TO-DO: Assign the INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO song_info (sessionid, item_in_session, artist_name, song_length, song_title)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        ## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], float(line[5]), line[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test output to confirm that song_info table has data\n",
      "\n",
      "23 0 Regina Spektor The Calculation (Album Version) 191.09\n",
      "23 1 Octopus Project All Of The Champs That Ever Lived 250.96\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Add in the SELECT statement to verify the data was entered into the table\n",
    "query_test1 = \"SELECT sessionid, item_in_session, artist_name, song_length, song_title FROM udacity.song_info LIMIT 2\"\n",
    "try:\n",
    "    rows = session.execute(query_test1)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"test output to confirm that song_info table has data\\n\")\n",
    "for row in rows:\n",
    "    print(row.sessionid, row.item_in_session, row.artist_name, row.song_title, round(row.song_length,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the output for query to provide artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
      "\n",
      "ARTIST                         SONG                                     DURATION\n",
      " \n",
      "Faithless                      Music Matters (Mark Knight Dub)          495.31    \n"
     ]
    }
   ],
   "source": [
    "# Actual query for song_info\n",
    "query_song = \"SELECT artist_name, song_title, song_length FROM song_info WHERE sessionid = 338 AND item_in_session = 4\"\n",
    "try:\n",
    "    rows = session.execute(query_song)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "  \n",
    "print(\"This is the output for query to provide artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\\n\")\n",
    "print(\"{: <30} {: <40} {: <10}\".format(\"ARTIST\", \"SONG\", \"DURATION\\n\"))\n",
    "\n",
    "for row in rows:\n",
    "    print(\"{: <30} {: <40} {: <10}\".format(row.artist_name, row.song_title, round(row.song_length, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUERY 2:\n",
    "### Give only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "### For this query I used composite Primary keys (userid, sessionid) to provide the best design for the query, since they will be how the result set will be stored.  The item_in_session field will be used for clustering and sorting, and in combination with the primary keys, provide the most efficient output for what is specified in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "query2 = \"CREATE TABLE IF NOT EXISTS artist_info (userid int, sessionid int,  item_in_session int, artist_name text, song_title text, \\\n",
    "          first_name text, last_name text, PRIMARY KEY((userid, sessionid), item_in_session))\"\n",
    "try:\n",
    "    session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "## TO-DO: Assign the INSERT statements into the `query` variable\n",
    "        query = \"INSERT INTO artist_info (userid, sessionid, item_in_session, artist_name, song_title, first_name, last_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        ## TO-DO: Assign which column element should be assigned for each column in the INSERT statement.\n",
    "        ## For e.g., to INSERT artist_name and user first_name, you would change the code below to `line[0], line[1]`\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9],line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test output to confirm that artist_info table has data\n",
      "\n",
      "System of a Down Sad Statue Emily Benson 58 768\n",
      "Ghostland Observatory Stranger Lover Emily Benson 58 768\n"
     ]
    }
   ],
   "source": [
    "query_test2 = \"SELECT userid, sessionid, item_in_session, artist_name, song_title, first_name, last_name FROM udacity.artist_info LIMIT 2\"\n",
    "try:\n",
    "    rows = session.execute(query_test2)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"test output to confirm that artist_info table has data\\n\")\n",
    "for row in rows:\n",
    "    print(row.artist_name, row.song_title, row.first_name, row.last_name, row.userid, row.sessionid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of query to provide only the following: name of artist, song (sorted by itemInSession) and user (first and last name)## for userid = 10, sessionid = 182\n",
      "\n",
      "ARIST                SONG                                                    USER FIRST NAME      USER LAST NAME      \n",
      "Down To The Bone     Keep On Keepin' On                                      Sylvie               Cruz                \n",
      "Three Drives         Greece 2000                                             Sylvie               Cruz                \n",
      "Sebastien Tellier    Kilometer                                               Sylvie               Cruz                \n",
      "Lonnie Gordon        Catch You Baby (Steve Pitron & Max Sanna Radio Edit)    Sylvie               Cruz                \n"
     ]
    }
   ],
   "source": [
    "#Actual query for artist_info to get artist info for userid = 10 and sessionid = 182\n",
    "query_artist = \"SELECT userid, sessionid, item_in_session, artist_name, song_title, first_name, last_name  FROM artist_info WHERE userid = 10 AND sessionid = 182\"\n",
    "try:\n",
    "    rows = session.execute(query_artist)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print(\"output of query to provide only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\\n\")\n",
    "print(\"{: <20} {: <55} {: <20} {: <20}\".format(\"ARIST\", \"SONG\", \"USER FIRST NAME\", \"USER LAST NAME\", \"USER ID\", \"SESSION ID\\n\"))\n",
    "\n",
    "for row in rows:\n",
    "    print(\"{: <20} {: <55} {: <20} {: <20}\".format(row.artist_name, row.song_title, row.first_name, row.last_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUERY 3:\n",
    "### 3. Give every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "### For Query 3, the primary keys song_title and user_id (which provides unique users) provide the best means to get the combination of user and song information that the query asks for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "query3 = \"CREATE TABLE IF NOT EXISTS user_info (song_title text, userid int, item_in_session text, first_name text, last_name text, \\\n",
    "           PRIMARY KEY(song_title, userid))\"\n",
    "try:\n",
    "    session.execute(query3)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create file for user info for users who listened to 'All Hands Against His Own'\n",
    "file = 'event_datafile_new.csv'\n",
    "with open(file, encoding = 'utf8')as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_info (song_title, userid, item_in_session, first_name, last_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[3], line[1], line[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test output to confirm that user_info table has data\n",
      "\n",
      "Wonder What's Next 49 3 Chloe Cuevas\n",
      "In The Dragon's Den 49 41 Chloe Cuevas\n"
     ]
    }
   ],
   "source": [
    "#test to see if any data was inserted into user_info table\n",
    "query_test3 = \"SELECT * FROM udacity.user_info LIMIT 2\"\n",
    "try:\n",
    "    count3 = session.execute(query_test3)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"test output to confirm that user_info table has data\\n\")\n",
    "for row in count3:\n",
    "    print(row.song_title, row.userid, row.item_in_session, row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER FIRST NAME      USER LAST NAME       QUERY SONG\n",
      "                                       \n",
      "Jacqueline           Lynch                All Hands Against His Own\n",
      "Tegan                Levine               All Hands Against His Own\n",
      "Sara                 Johnson              All Hands Against His Own\n"
     ]
    }
   ],
   "source": [
    "query_user = \"SELECT userid, first_name, last_name, song_title FROM user_info WHERE song_title = 'All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(query_user)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"{: <20} {: <20} {: <50}\".format(\"USER FIRST NAME\", \"USER LAST NAME\", \"QUERY SONG\\n\"))\n",
    "\n",
    "for row in rows:\n",
    "    print(\"{: <20} {: <20} {: <20}\".format(row.first_name, row.last_name, row.song_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Drop the table song_info before closing out the sessions\n",
    "drop_query1 = \"DROP TABLE IF EXISTS song_info\"\n",
    "try:\n",
    "    session.execute(drop_query1)\n",
    "except Exeption in e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Drop the table artist_info before closing out the sessions\n",
    "drop_query1 = \"DROP TABLE IF EXISTS artist_info\"\n",
    "try:\n",
    "    session.execute(drop_query1)\n",
    "except Exeption in e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Drop the table user_info before closing out the sessions\n",
    "drop_query3 = \"DROP TABLE IF EXISTS user_info\"\n",
    "try:\n",
    "    session.execute(drop_query3)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
